{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ![title](http://blog.varunajayasiri.com/ml/lstm.svg)\n",
    "\n",
    "# LSTM in  NumPy\n",
    "I wanted to understand the inner workings of an LSTM Recurrent Neural Network which led me to scour the internet for links.  The best link by far is [Christopher Olah's blog post](http://colah.github.io/posts/2015-08-Understanding-LSTMs/). I've been using LSTM's for awhile with Keras and TensorFlow, however these libraries don't help you understand the nuts and bolts of a Long Short Term RNN.\n",
    "\n",
    "I attempted to implement the network in NumPy, but because of a lack of time I had to give up.  Instead, I found Nick Jimenez's python classes to be highly useful:\n",
    "NumPy taken from [Nicolas D. Jimenez's GitHub](https://github.com/nicodjimenez).  \n",
    "\n",
    "I used 10 rows from my wind direction dataset and converted the wind direction to a sine wave.  I made a few adjustments to the network such as Adam optimization.  Below I walkthrough the network in English, mostly as an exercise for myself to understand the memory in backpropagation.\n",
    "\n",
    "#### Adam Optimization\n",
    "I implemented Adam optimization to the network rather than using SGD.  I used a GitHub page to help me write this, but I can't seem to find the link now.  Below I graphed a learning comparison of Adam vs SGD, both with a learning rate of 0.1. \n",
    "\n",
    "An interesting note on Adam optimization was that the network was only able to learn well with Adam optimization after initializing weights to <br>\n",
    "(np.random.rand(*args) * (.2) -.1)*.1<br>\n",
    "Very low weight initialization was required for the network to learn the data with Adam; Adam optimization only worked well after the \"*.1\" was added.  Adam optimization did however learn more effectively than SGD after this modification.  With the original original SGD weight initialization, the final loss on the network with this data was 0.18.  After adjusting the weight initialization, SGD loss was .26 and Adam loss was .0013.\n",
    "Training SGD for more iterations would make up for its learning deficiencies compared to Adam.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Turbine name: R80736\n",
      "Training...\n",
      "iter  0: y_pred = [-0.00022,  0.00051,  0.00034,  0.00070,  0.00028,  0.00122], loss: 3.332e+00\n",
      "iter 50: y_pred = [ 0.47206, -0.16051,  0.51563,  0.52871, -0.54239, -0.49950], loss: 8.613e-01\n",
      "Actual vs Predicted:\n",
      "[ 0.64447554 -0.92569097  0.6678121   0.9735639  -0.68801814 -0.43752836]\n",
      "[0.5869153998588292, -0.4670886537363172, 0.5520156916916225, 0.7768378584348697, -0.7074944282921246, -0.4815653387488001]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAElCAYAAAALP/6mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJzt3XmcXFWd9/HPt9cEsrAkQBMiYUdgBKRFeEaWR4LKIhhEA8gADgxJUHFGccZlRkccHp1nHMcVMS4gDsPgI4FBRAQVSKImkCCgCCo0hCSE0EDIRtJJd/+eP+6t4qaoXtPVtX3fvOpF1T23bp1b1alfnfM751xFBGZmZgAN5a6AmZlVDgcFMzPLc1AwM7M8BwUzM8tzUDAzszwHBTMzy3NQMBsBko6T9MdhPvd1kjZIaqyUOln9clCwspH0Fkm/lrRW0kuSfiXpTZnyNknflvRs+qXZIek6SQen5dMkRVq2QdJqSbdLOnmA15Wkj0n6s6RNkp6R9HlJrUOoe0jaP/c4IhZExEHDeR8i4pmIGBcRPcN5finqZPXLQcHKQtIE4Hbga8AuwBTgs0BXWr4r8GtgB+A4YDzwRuA+oPBLf6eIGAccDtwN3CLpon5e/qvApcAF6XFPAU4CfjgCp2ZW3SLCN99G/Qa0Ay/3U/4vwMNAQz/7TAMCaCrYfgWwuthzgQOAHuDogu1TSQLSW9PH1wHXkASZ9STBaO+0bH76uhuBDcBM4ERgReZ4TwMfAx5J9/susDvw0/R4Pwd2LjwP4Nj0mLnbZuDpdL+jgd8ALwOrgK8DLUOo0+uBe9PnPwqckSm7DvgG8JO0fouB/cr9d+Lb6N/cUrBy+RPQI+n7kk6RtHNB+XTglojoHcax5wG7AcW6Tk4i+aK8P7sxIpYDi9i2FfI+4HPAJOAh4IZ03+PT8sMj6fa5qY96vDs93oHAO0kCwieBySSt9MsLnxARv0mPOQ7YmeTL+ca0uAf4u7Q+x6bnctlg6iSpGfgxcFf63nwIuEFS9j06h6S1tjPwBHBVH+dlNcxBwcoiItYBbyH5dfttoFPSbZJ2T3eZBDyX21/SGZJelrRe0l0DHP7Z9P+7FCmbRPIru5hVaXnOTyJifkR0AZ8CjpU0dYDXzvpaRKyOiJXAAmBxRPw2IjYDtwBHDvD8r5L8av8UQEQsjYhFEdEdEU8D3wJOGGRdjgHGAV+IiC0R8UuS7rtzM/vcEhH3R0Q3SQA8YpDHthrioGBlExGPRcRFEbEXcBiwJ/DltPhFoC2z720RsRPJL+WWAQ49Jf3/S0XKXsget0BbWp6zPPP6G9Lj7TnAa2etztzfVOTxuL6eKGkWSffPebnWkqQD00T6c5LWAf+HbYNYf/YElhe0vJbx6nsFmSAMvNJf/ax2OShYRYiIx0n6tQ9LN/0CeJek4fyNzgCeB4oNx/wlMFXS0dmNaQvgmPR1c6ZmyseRtDyepcQkHUfSbXVm2qLK+SbwOHBAREwg6YrSIA/7LMl5Z9/P1wErR6DKVkMcFKwsJB0s6aOS9kofTyXpyliU7vIlkr7tH0jaLx1GOp5+ujQk7S7pg8BngE8Uy0dExJ9IEsg3SDpGUqOkQ4GbgZ9HxM8zu5+aDpttIfmSXpTmHiD51b/vdrwFfZ3DVJJRUBekdc0aD6wDNqTDcucUlPdXp8Ukv/7/XlKzpBNJ8hz/PVJ1t9rgoGDlsh54M7BY0kaSYPB74KMAEfECyS/3zcDCdP+HSL4YC78MX06P8TvgVOA9EfG9fl77g8B3gP8kGalzJ8monHcX7PdfJAHmJeAo4PxM2T8D30/zHO8d7EkPwkkko5R+lJl/8WhadgVwHsl78W2gMMHdZ50iYgtJEDiFpIvsapLA8/gI1t1qgCJ8kR2zQpKuIxml9I/lrovZaHJLwczM8hwUzMwsz91HZmaW55aCmZnlOSiYmVmeg0KdkfS0pOnlrkeOpJMkPS7pFUn3SNq7j/12k3Rjuoz22nSZ7TcX7DNZ0n+l5Wsk3ZAp20XSTZJelPSCpBvSlVpz5dPS138lrc/0TNlFknoyQ0Q3pOP8s9dCyN5C0kfT8k8WlG2S1CtpUlr+aEF5t6Qfp2XH9XHsd6flF0paKmmdpBWS/q+kpky9/1PSqrT8T5IuyZQdImlJ+j6tkfRzSYdkyv93+n6slfR0kc/jHkmd6bEflnRmpmx7znlS+tm+mA6t/Y2kv+z/r8hGVLlX5PNtdG8kq3dOL3c90rpMAtYC7wHGAP9GMkGs2L77Ah8hWYqikWTp6xeAcZl9FpBMepsINANHZsquJlkMbkJa/nPgS5ny36TPHUsyX+FlYHJadhGwcJDntA/JwnXT+ij/Z+CXfZQJeIpk/kCx8hNJ5ijsmD6eQ7KseAvJchVLgY9n9j8UaE3vH0yyjMVR6eOdSFZnVfp+Xg48knnu0cBfpe/z00Xq8gbS1WlJ5pusB9q295zTv4ODSH6wCngXyTyRpmLP923kb2WvgG+j/IH3ERSAvyFZGfMl4DZgz3S7gP8gWTZiHckEscPSslOBP6RfCCuBK4ZYl0uBX2ce70iyJtDBg3z+usyX3NvSc2vsY9+fApdlHn8A+Fl6/0CSZbPHZ8oXALPT+0MJCp8B7umjTEAHcGEf5Sdkv/SLlF8LXNvPa38E+HEfZQeRLPj33iJlTen78UqRsunFgkLBPkeTTDI8ukjZsM85DQzvJFk0cbdS/Hvw7bU3dx8Zkt4KfB54L8kv8WW8uvzB24DjSb44J6b7vJiWfReYFRHjSdYs+mV6vNelTf++buelzz+U5JoJAETERuDJdPtAdT6C5BfyE+mmY0jWOvp+2vXwgKTsCqLfAE6XtLOSZbrfTRIocvXoiIj1mf0fLqjHkWm3058k/VO2myZTJ5FcuOf7fVT7OJJlq2/uo/xC4Ob0fSg89o7A2f0cG5LP6dHsBklXS3qFZM2kVcAdBeUvk3yhf41kgb1BU7I432aSJTTuBZYU2W1Y5yzpkbRetwHfiYjnh1I3G77X/GFbXXof8L2IeBBA0ieANZKmAVtJlpY4GLg/Ih7LPG8rcIikhyNiDbAGkstLknRPDGQc0FmwbW36en1KcwE/AD4bEWvTzXuRBLBLgPeTfOn/j6T9I1ky40GSIJILaL8g6VLK1SN3nGw9ciuIzicJestIAsVNQDdJIM16C+kSFX1U/ULgR5GsuFp4TjuQfOmf0cdzzyLpLruvWKGkvya5cNEl2e0RcZmkD5Fcf+FE0ivbZcp3SgPOhen5DVpEnK7kOg3TgddH8WtfDOucI+INksaQLG440Kq4NoLcUjBIllXOfyGk/4BfBKZEsu7+10l+aT8vaW4mQftuki6kZZLuk3TsEF93A0kff9YEku6EoiSNJblYzKKIyH4pbyLp5vhuRGyNiP8mWfo6l6T8IcmFfcanr/EkydpHA9YjIjoi4qmI6I2I3wFXknyZFcr96u3rC/A99P1L/yySrruiX/rpsa+PtF+l4NjvIglQp6QBcBsR0RMRC0kCZ+G6UbkW2jXA9ZJ26+P1i0rf658Cb5O0zZf79p5zRGyOiBuBj0s6fCj1suFzUDBIllXOj/pJfznuSrqsckR8NSKOAg4h6Ub6WLr9gYg4k6R74FbSaxyr+Iic7O196Us9SnJd5ezr7kdBF0imvDV9nRXArILiR0j6nrOyj48AvhURG9Mv7WtIAlquHvsqWYU15/C+6pEed5slq9Ng1d8X4AySL8B7+yjv70t/Ksmv/OuLlL2DZHG8d6YBqz9NJO9vMQ0k18Oe0kf5QIode9jnXKCZEqxIa30od1LDt9G9kSRjTyEZ5ZG7TSfpxjkCaAW+QppYBd5EMrqkmSQRfCfJJRtbSLqdJqb7XQwsG2JdJpN007w7rce/0vfoo9zlJG+lyEgUkmsdrCH5omkk+SX/EjApLb+HpN98bHq7mm2T3IuAL6b1mMG2o49OAXZP7x9MsprrZwpe/7z0vVUf9b8LuLKPsr1IuqOKXhOZ5LoJ84tsfytJi+74ImW7kVxec1z6fryd5PrNZ6TlJ5Nc+a2RpFX0VZIfB2PS8ob0vTiFpBU5hlevB31wun1s+rmcD2wB3ri950ySG3pL+vc1FvgHkhbbnuX+t1Mvt7JXwLdR/sCTL64ouP0LMJukS+Ulkss07pXufxLJr/ANJH3aN6RfNC0kAWINySigB4C3DKM+00mSoJtIflFOy5RdA1yT3j8hresrbHth++My+x9HMjpqA0nSM1u2D0lQeTE9xztJLlaTK5+Wvv4mkoT19EzZF0muVbCRZCTNlUBzwXn8DPhcH+c4Jf0C3L+P8k8AC/p5jx4HLi6y/Z70uNn346dp2WSSbpmXeXXU2N9knvue9LgbSH4Q/AR4Q6b8xCJ/J/emZa8nSS6vT4//ADBjJM45/ZwfTo+d61p6TdDzrXQ3r31kZmZ5zimYmVmeg4KZmeU5KJiZWZ6DgpmZ5VXdjOZJkybFtGnTyl0NM7OqsnTp0hciYvJA+1VdUJg2bRpLlhRbYsXMzPoiaVDLmLj7yMzM8hwUzMwsz0HBzMzyHBTMzCzPQcHMzPLqJiisWr+KE647gec2PFfuqpiZVay6CQqfm/85Fj6zkCvvu7LcVTEzq1hVt0pqe3t7DGWewtirxrK5e/Nrto9pGsOmT20ayaqZmVUsSUsjon2g/Wq+pdBxeQfnHXYerY2tADQ3NPO+v3gfT334qTLXzMys8tR8UGgb38aE1gls7d1KAw1s7d3KmKYx7DFuj3JXzcys4tR8UABYvXE1s4+azQ/O+gEAC55ZUOYamZlVpqpb+2g45s2cl7//kz//hJv/cDPHfOcYbj3nVrcYzMwy6qKlkHXVW69ia89WFq9c7JFIZmYFan70UZZHIplZvfLooyJyI5HGNo0FoEENnPcX53kkkplZqq6CQm4kUldPF80NzfRGL50bO51XMDNL1VVQgFdHIi26eBG7jt2Vhc8s5Mk1T3oJDDMz6iynUGj+svmccN0JtLe18+BzDzLrqFlcfdrVI3JsM7NKMticQl0HBSeezaxeONE8CB2Xd3DGQWfkH+/QtIOXwDCzulbXQaFtfBt7jtsTIQA2dW9iQusEJ57NrG7VdVCAJPF86VGX8roJr2NC6wQ61nQ46Wxmdavug8K8mfO45vRrmPvOuaztWsuaTWt83QUzq1t1nWjOctLZzGqZE81D1HF5B2cedGb+sZPOZlaPHBRSbePbaBvX5qSzmdU1B4WMXNL5gF0OYIfmHXjipSecdDazulKyoCBpjKT7JT0s6VFJny2yT6ukmyQ9IWmxpGmlqs9g5JLO18+4nle2vsJzG55z0tnM6krJEs2SBOwYERskNQMLgQ9HxKLMPpcBb4iI2ZLOAWZExMz+jluqRHOWk85mVmvKnmiOxIb0YXN6K4xAZwLfT+//CDgpDSZl1XF5B2e//uz847FNY510NrO6UNKcgqRGSQ8BzwN3R8Tigl2mAMsBIqIbWAvsWuQ4l0paImlJZ2dnKasMJEnnSTtMyiedN3dvdtLZzOpCSYNCRPRExBHAXsDRkg4b5nHmRkR7RLRPnjx5ZCvZh9UbVzO7fTbH7308DWrgsc7HnHQ2s5rXNBovEhEvS7oHeAfw+0zRSmAqsEJSEzAReHE06jSQeTPnAbB87XIOufoQnlzzJCvXr+TK+6708tpmVrNKOfposqSd0vtjgZOBxwt2uw24ML1/NvDLqLAp1gd+/UA2bNnA8nXL6Y1evrnkm+izYuxVY8tdNTOzEVfK7qM24B5JjwAPkOQUbpd0paTcetXfBXaV9ATwEeDjJazPsHRc3sG5h51LQ/pWOelsZrWsZN1HEfEIcGSR7Z/O3N8MvKdUdRgJbePbmNg6kUgHTnmms5nVMs9oHoTVG1czp30Os46aBcADKx9w0tnMatKoJJqrXS7p3NXdxfxl83nshcfYtHWTk85mVnO8dPYQeKazmVWrss9orkUdl3dw3mHn0dSQNLBaG1uddDazmuKgMARt49uY0DqB3ugFoKunix2ad3DS2cxqhoPCEK3euJrZR83O5xJ+8dQvnHQ2s5rhRPMQ5ZLOkIxCuvaha3lqzVNOOptZTXCieZicdDazauJEc4nlks4tjS0ANDc0O+lsZlXPQWGYcknn7t5uGtTA1t6trO9az8wfzXR+wcyqloPCdsglne8+/25aG1u588k7fflOM6tqzimMAOcXzKzSOacwivIrqSp5O8c0jXF+wcyqkoPCCMivpJq2ujZ3b2Z8y3hPajOzquOgMEJyK6l++vhkZfAFyxZ4UpuZVR1PXhshuUltEcGvlv+K+cvm0/1Ctye1mVlVcaJ5hDnpbGaVyInmMslNamtuaAagpbHFSWczqxoOCiMsN6mtJ3oQYkvPFhrV6KSzmVUFB4USyE1qu/WcW2lUI3c+cScnXOuks5lVPieaSyC7kuoXpn+Bj939MTqf6XTS2cwqnhPNJeSks5lVCieaK0Au6TymaQwAjWp00tnMKlrJgoKkqZLukfQHSY9K+nCRfU6UtFbSQ+nt06WqTznkks5berbQ1NBET/SwYu0Kr6RqZhWrlC2FbuCjEXEIcAzwAUmHFNlvQUQckd5qbnnRXNJ50cWLmLTDJBY8s4CFy7ySqplVplHLKUj6H+DrEXF3ZtuJwBURcfpgj1NNOYUs5xfMrJwqKqcgaRpwJLC4SPGxkh6W9FNJh/bx/EslLZG0pLOzs4Q1LR1PajOzalDyoCBpHHAz8LcRsa6g+EFg74g4HPgacGuxY0TE3Ihoj4j2yZMnl7bCJVJsUltzQ7MntZlZRSlpUJDUTBIQboiIeYXlEbEuIjak9+8AmiVNKmWdyimXX/jh2T9EKJnU5pVUzayClGzymiQB3wUei4gv9bHPHsDqiAhJR5MEqRdLVadyy05q+9yLn+Mf7/lHVm9c7UltZlYxSpZolvQWYAHwO6A33fxJ4HUAEXGNpA8Cc0hGKm0CPhIRv+7vuNWaaM5y0tnMRttgE80laylExEJAA+zzdeDrpapDpeq4vIMr7rqCeY/PY3P3ZhrVyMzDZvLvb/v3clfNzOqcZzSXQbFJbcvWLPOkNjMrOweFMsklnRdfvJg9dtyDX6/4NQuWLfCkNjMrKy+IV2bOL5jZaKioyWvWt8JJbc0NzZ7UZmZl46BQZtlJbQ1qYGvvVnqix5PazKwsHBQqQC6/cOf5d9La2Modf76D46893klnMxt1zilUmJv/cDNn/7+zEWJ2+2xPajOzETHYnIKDQgVx0tnMSsWJ5iqUSzqPbRoLgBDvOeQ9Tjqb2ahxUKgguaRzV08XLY0tBMFDzz1ERHjhPDMbFQ4KFSaXdL7/kvt5055v4s8v/Znzbzmfhc/4am1mVnrOKVQw5xjMbKQ4p1ADOi7v4IyDzsg/Hts01hPbzKykHBQqWNv4NvYctydKF5vd1L0pWVHVC+eZWYk4KFS41RtXM6d9Duccdg4Adz55p/MLZlYyzilUCecXzGx7OKdQYzou7+CdB74z/9j5BTMrBQeFKtE2vo0p46c4v2BmJeWgUEVy+YUL3nABAD994qfOL5jZiHJOoQo5v2BmQ+WcQg3ruLyDGQfPyD92fsHMRoqDQhVqG9/G7jvuvk1+QZLzC2a23RwUqlQuv/Dp4z8NwG1/vM35BTPbbiXLKUiaClwP7A4EMDcivlKwj4CvAKcCrwAXRcSD/R3XOYVtOb9gZoNRCTmFbuCjEXEIcAzwAUmHFOxzCnBAersU+GYJ61OTOi7v4JxDz6FByUfZ2tjq/IKZDVvJgkJErMr96o+I9cBjwJSC3c4Ero/EImAnSW2lqlMtahvfxk5jdoJILsrT1dPFpq2bnF8ws2EZlZyCpGnAkcDigqIpwPLM4xW8NnAg6VJJSyQt6ezsLFU1q9bqjauZ3T6bW2beQktjCz/+049ZuMz5BTMbupLPU5A0DrgPuCoi5hWU3Q58ISIWpo9/AfxDRPSZNHBOoW/OL5hZXyohp4CkZuBm4IbCgJBaCUzNPN4r3WbDkLvGc0tjCwCNamTGwTM4Yo8j3JVkZoNSsqCQjiz6LvBYRHypj91uAy5Q4hhgbUSsKlWdal3uGs/dvd00NTTREz0seGYB96+8311JZjYopWwp/CXwV8BbJT2U3k6VNFvS7HSfO4AO4Ang28BlJaxPXchd4zk3GumFV16gN3r55pJvos+KsVeNLXMNzaySDSqnIGk/YEVEdEk6EXgDyaihl0tcv9dwTmFwVq1fxUfu+gg/fPSH9EYvLY0tnH7A6Ty74VlumXkLe4zbo9xVNLNRNNI5hZuBHkn7A3NJ8gD/tR31sxJrG9/GTq07AclQ1S09W1j67FJ3JZlZvwYbFHojohuYAXwtIj4GeD5Bhct1JTU3NgOwbN0ydyWZWb8GGxS2SjoXuBC4Pd3WXJoq2UiZN3Me3zjtGzz94aeZcfCM/AJ6YxrHeNazmRU12KDwfuBYkrkGT0naB/hB6aplIym3qmrO5p7NrOta51nPZvYagwoKEfGHiLg8Im6UtDMwPiL+tcR1sxGUW1X1tnNuY4emHfjJn37CgmULnF8ws20MdvTRvcAZQBOwFHge+FVEfKSktSvCo4+2j2c9m9WnkR59NDEi1gFnkQxFfTMwfXsqaOWRm/U8pmlMftvJ+57sWc9mBgw+KDSlq5e+l1cTzVaFcrOet/RsobWxFYBfPvVLFq9Y7K4kMxt0ULgS+BnwZEQ8IGlf4M+lq5aVUm6oapB0HfZED0F4qKqZlX6V1JHmnMLIWbV+FVfcdQXzHp+XzzOcuPeJbO7Z7FnPZjVmRHMKkvaSdIuk59PbzZL22v5qWjkV60q6b9l97koyq2OD7T66lmRF0z3T24/TbVblCruSIv0v15XU8NkGJ6DN6shgg8LkiLg2IrrT23XA5BLWy0ZJdtbzeYedx9imV/MJe+yYdB+51WBWPwYbFF6UdL6kxvR2PvBiKStmoyvXldTV05Xf9tzG55yANqszgw0Kf00yHPU5YBVwNnBRiepkZZLrSrr7/LvZb+f98tubG5p9BTezOtE0mJ0iYhnJjOY8SX8LfLkUlbLymDfz1SumnrzvyTz14FMIsbV3K/c+dS9rt6zlyvuu5OrTri5jLc2slLbnymujvsSFjZ5cq6GxoRGANV1rvOy2WR3YnqCgEauFVZzCBHRzQ7JSeoMaOG3/09yVZFajticoVNesNxuWXAK6J3pobmimN3q5q+Muz2Uwq1H9BgVJ6yWtK3JbTzJfwepAritJShqHW3u3elSSWY3qNyhExPiImFDkNj4iBpWktupX2JWUXWH1uNcdx6KLF3HCdSe4O8msBmxP95HVmWLLYix4ZgGzbp/FwmcWujvJrAY4KNiQ5LqSFl+ymEYlI5MWr1y8zcgkL41hVr1KFhQkfS9dPO/3fZSfKGmtpIfS26dLVRcbObmupMP3OJzlf7eccw87l6aGpCexQQ3su9O+gJfGMKtWpWwpXAe8Y4B9FkTEEenN3yJVpm18GxNbJ9IbvQD0Ri8dL3c4CW1WxUoWFCJiPvBSqY5vlSG7NMbU8VPz21sbWznr4LM8n8GsypQ7p3CspIcl/VTSoWWuiw1Drjtp+n7TOe3A01D6X1dPFwuXL+T+lfe7K8msipQzKDwI7B0RhwNfA27ta0dJl0paImlJZ2fnqFXQhmb1xtXMaZ9Dc2My+/n5jc87AW1WZcoWFCJiXURsSO/fATRLmtTHvnMjoj0i2idP9mUcKlV2PsO5h52bXxpDiGkTpwFOQJtVurIFBUl7KJ0iK+notC6+RkMNyCWge6IHSK7m9vTap52ANqsCpRySeiPwG+AgSSskXSxptqTZ6S5nA7+X9DDwVeCciPB6SjUim4Dee+Le+e2+NoNZZVO1fQ+3t7fHkiVLyl0NG4I5t89h7tK5oGTY6oSWCWzYuoFZR83ytRnMRomkpRHRPtB+5R59ZHVg9cbVzG6fnZ/ktm7LOiegzSqUg4KVXOGCerl1kwDaxrUBTkCbVQoHBRs1uQX1tvZuzW9btWHVNglotxrMystBwUZVNgG9/877o/QCfg00eNiqWQVwotnKZs7tc5j74Nz82kmFxjSNYdOnNo1yrcxqkxPNVvH6Grba1NDEuw56l4etmpWBr55mZTNv5rz8/VP2P4W5D85FiO7ebu588k66uru48r4rPWzVbBS5pWAVIddqaGxILtyzuXuzE9BmZeCgYBWhv+tAT2iZADgBbTYaHBSsomSvA52zbss6txrMRomDglWcbAL6gF0OoEGv/plOGpsspOtWg1lpeEiqVbSBhq0K8exHn2WPcXuMcs3MqouHpFpNKGw15Ca7AeyxYxII3GowGzluKVjVcKvBbPjcUrCa09cSGeCF9cxGilsKVpXcajAbGrcUrKb112rYc9yegFsNZsPhloJVPbcazAbmloLVjWyrYb+d93OuwWw7uKVgNWWgVkNrYytv3uvN3HT2TW45WF1xS8HqUn+5hqOnHM3MQ2ey8JmFbjmY9cEtBatZuVZDc0MzXT1dRfdxvsHqhVsKVvdyrYbFlyzmgjdcwM5jds6XNTU0sd/O+wHON5hluaVgdWPO7XOYu3QuvXiUktWfsrcUJH1P0vOSft9HuSR9VdITkh6R9MZS1cUM0pZDe5JvmDJ+Sn57gxqYNnEa4FaDWclaCpKOBzYA10fEYUXKTwU+BJwKvBn4SkS8eaDjuqVgI8FzG6zelL2lEBHzgZf62eVMkoAREbEI2ElSW6nqY5aVHaW0z077bFOWXX111fpVnHDdCb6oj9WNciaapwDLM49XpNteQ9KlkpZIWtLZ2TkqlbPalrv85/T9pvP2/d6+zYV8ntv4XP5Kb3t+aU/mL5vvbiWrG1Ux+igi5kZEe0S0T548udzVsRrT39yGHF8K1OpFOYPCSmBq5vFe6TazUZVtNUzfdzqSaG1o3WafpoYm9t15X8DJaKtt5QwKtwEXpKOQjgHWRsSqMtbH7NW5DX+zmEMnHZrf3t3bTceajny3klsNVqtKOST1RuA3wEGSVki6WNJsSbPTXe4AOoAngG8Dl5WqLmaDlWs1HL7H4Rw46UAua7+Mu8+/m6kTXm3UCrH7jrsDTkZb7fGI+SniAAALPUlEQVTkNbNBGGgIK8Cc9jlcfdrVo1grs8Er+5BUs1qSTUYfsMsBNBT5p+NuJasFDgpmg5BNRp+0z0mgZBnurAY15GdKu1vJqpWDgtkQZRfayyaje6OXletXeo6DVTXnFMy2w1k3nUXbuDZmHDyD2T+ZnR+hVIyXzrByck7BbBRku5VO3vfkZI5DQbeSkJfOsKrhoGA2QvrqVgrCS2dY1XD3kVkJZLuVLrvjMp586Ulfx8HKyt1HZmXU32il7NpKE1omAK8uneGuJSs3BwWzEivsVsomotdtWbfN0hlT/2MqC59Z6NyDlY27j8xG0Wu6ldY82e8safBMaRsZg+0+clAwK5Pc0hktjS10dXex24670bmx07kHKwnnFMwqXK5badHFi5jTPoexzWNB0NzQvM1+DTSw2467AR7SaqXnloJZhch1LV161KW87+b38egLj/a7/5z2OfzT8f/EOTefw01n3+QWhPXL3UdmVWyouQcHCBuIu4/MqthrhrTy6pDW7PWkcwonxbmLyYbLQcGswhUOae2N3qJzHnIcIGx7uPvIrIoUyzu0NrbS1dOFUJ+L8YG7mOqdcwpmNa5ogGhopau3a8DnOkDUHwcFszpSLEC0NLSwpXfLgM91gKgPDgpmdcoBwopxUDAzBwjLc1Aws230FyCcpK59Dgpm1qftHcV09WlXs2r9KgeJKlIRk9ckvUPSHyU9IenjRcovktQp6aH0dkkp62NmidzkuMP3OJwDJx3IZe2XbbO0d36iXJGviNwy33t9aa+iy3x7XkR1K1lLQVIj8CfgZGAF8ABwbkT8IbPPRUB7RHxwsMd1S8GsdPprQTSoYVDLfAN8a+m3mHXULHc5VZCydx9JOhb454h4e/r4EwAR8fnMPhfhoGBWkYoFiDFNY+jq7mLqxKmsWr+Krb1bB3Us5yTKrxK6j6YAyzOPV6TbCr1b0iOSfiRparEDSbpU0hJJSzo7O0tRVzMrUKyLKbfMd4Ma6ImefDdToxr7PVZ/S2+4u6mylLKlcDbwjoi4JH38V8Cbs60CSbsCGyKiS9IsYGZEvLW/47qlYFZ+fbUiNndvBpJrQgymFeHuptFTFd1HBfs3Ai9FxMT+juugYFZZsgFixk0zALhl5i1DHtWUVdjdFBEOFtupEoJCE0mi+SRgJUmi+byIeDSzT1tErErvzwD+ISKO6e+4Dgpm1aG/pHWjGumJnkEdZ/ZRs5FUtDXhYDF4ZQ8KaSVOBb4MNALfi4irJF0JLImI2yR9HjgD6AZeAuZExOP9HdNBwaz6DNTdNNhJdFnuehqaiggKpeCgYFbdBtvdNJTWRFaxyXVuUTgomFmVGag1MZT5EpBOvBPMOmoWULxFUU/BwkHBzKrWQK2JYiOdhtL1BP13P9VisHBQMLOaM5hg0dXdxd4T9+bZDc+ypWfg1WALDTZYVFvgcFAws7qRDRZzl87ljifu4Jm1z9DS2DLs7qdChaOgoLpaGQ4KZla3htL9tL3BIquSWxkOCmZmBbYnWAw1Z5FVGCyy90drpJSDgpnZIA0lWGTvN6mJ7ujeroABydpRQZS0W8pBwcxsO/UVLAYKHLnJeCPRJQWvzWdcfdrVQz6Gg4KZ2SgYbiujpbGFLT1b2GXMLqztWjvkiXpjmsaw6VObBr3/YINC05BqYWZm25g3c17+fseHO/L3D5x0ICdMO6HfVkZupNTLXS/329IQAiAIdmjagRmvn8EX3/bFkpyPWwpmZmU01JbGlp4tw+pCckvBzKwKDLWlMXfpXFZtWFWy+rilYGZWByrhcpxmZlZlHBTMzCzPQcHMzPIcFMzMLM9BwczM8hwUzMwsr+qGpErqBJYN8+mTgBdGsDrVoh7Pux7PGerzvOvxnGHo5713REweaKeqCwrbQ9KSwYzTrTX1eN71eM5Qn+ddj+cMpTtvdx+ZmVmeg4KZmeXVW1CYW+4KlEk9nnc9njPU53nX4zlDic67rnIKZmbWv3prKZiZWT8cFMzMLK9ugoKkd0j6o6QnJH283PUpBUlTJd0j6Q+SHpX04XT7LpLulvTn9P87l7uupSCpUdJvJd2ePt5H0uL0M79JUku56ziSJO0k6UeSHpf0mKRj6+GzlvR36d/37yXdKGlMLX7Wkr4n6XlJv89sK/r5KvHV9PwfkfTG4b5uXQQFSY3AN4BTgEOAcyUdUt5alUQ38NGIOAQ4BvhAep4fB34REQcAv0gf16IPA49lHv8r8B8RsT+wBri4LLUqna8Ad0bEwcDhJOde05+1pCnA5UB7RBwGNALnUJuf9XXAOwq29fX5ngIckN4uBb453Beti6AAHA08EREdEbEF+G/gzDLXacRFxKqIeDC9v57kS2IKybl+P93t+8C7ylPD0pG0F3Aa8J30sYC3Aj9Kd6mp85Y0ETge+C5ARGyJiJepg8+a5IqRYyU1ATsAq6jBzzoi5gMvFWzu6/M9E7g+EouAnSS1Ded16yUoTAGWZx6vSLfVLEnTgCOBxcDuEZG7ft9zwO5lqlYpfRn4e6A3fbwr8HJEdKePa+0z3wfoBK5Nu8y+I2lHavyzjoiVwBeBZ0iCwVpgKbX9WWf19fmO2HdcvQSFuiJpHHAz8LcRsS5bFskY5JoahyzpdOD5iFha7rqMoibgjcA3I+JIYCMFXUU1+lnvTPKreB9gT2BHXtvFUhdK9fnWS1BYCUzNPN4r3VZzJDWTBIQbIiJ3RfDVuaZk+v/ny1W/EvlL4AxJT5N0Db6VpL99p7SLAWrvM18BrIiIxenjH5EEiVr/rKcDT0VEZ0RsBeaRfP61/Fln9fX5jth3XL0EhQeAA9IRCi0kianbylynEZf2o38XeCwivpQpug24ML1/IfA/o123UoqIT0TEXhExjeSz/WVEvA+4Bzg73a2mzjsingOWSzoo3XQS8Adq/LMm6TY6RtIO6d977rxr9rMu0NfnextwQToK6RhgbaabaUjqZkazpFNJ+p0bge9FxFVlrtKIk/QWYAHwO17tW/8kSV7hh8DrSJYdf29EFCawaoKkE4ErIuJ0SfuStBx2AX4LnB8RXeWs30iSdARJYr0F6ADeT/JDr6Y/a0mfBWaSjLb7LXAJSf95TX3Wkm4ETiRZIns18BngVop8vmmA/DpJV9orwPsjYsmwXrdegoKZmQ2sXrqPzMxsEBwUzMwsz0HBzMzyHBTMzCzPQcHMzPIcFKxuSdqQ/n+apPNG+NifLHj865E8vlmpOCiYwTRgSEEhM3u2L9sEhYj4X0Osk1lZOCiYwReA4yQ9lK7V3yjp3yQ9kK5NPwuSiXGSFki6jWQWLZJulbQ0Xd//0nTbF0hW8XxI0g3ptlyrROmxfy/pd5JmZo59b+b6CDekE5LMRtVAv3bM6sHHSWdBA6Rf7msj4k2SWoFfSbor3feNwGER8VT6+K/TGaVjgQck3RwRH5f0wYg4oshrnQUcQXL9g0npc+anZUcChwLPAr8iWdNn4cifrlnf3FIwe623kawj8xDJEiG7kly8BOD+TEAAuFzSw8AikgXJDqB/bwFujIieiFgN3Ae8KXPsFRHRCzxE0q1lNqrcUjB7LQEfioifbbMxWVdpY8Hj6cCxEfGKpHuBMdvxutm1enrwv08rA7cUzGA9MD7z+GfAnHQZciQdmF7AptBEYE0aEA4muQRqztbc8wssAGameYvJJFdPu39EzsJsBPiXiBk8AvSk3UDXkVyLYRrwYJrs7aT45R3vBGZLegz4I0kXUs5c4BFJD6bLeOfcAhwLPExygZS/j4jn0qBiVnZeJdXMzPLcfWRmZnkOCmZmluegYGZmeQ4KZmaW56BgZmZ5DgpmZpbnoGBmZnn/HxBN48ced0hRAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "iter  0: y_pred = [-0.00022,  0.00051,  0.00034,  0.00070,  0.00028,  0.00122], loss: 3.332e+00\n",
      "iter 50: y_pred = [ 0.62422, -0.83417,  0.63624,  0.81116, -0.69211, -0.53279], loss: 4.525e-02\n",
      "Actual vs Predicted:\n",
      "[ 0.64447554 -0.92569097  0.6678121   0.9735639  -0.68801814 -0.43752836]\n",
      "[0.6452756994939641, -0.9033736746297787, 0.6690755544839511, 0.9535165763784924, -0.6837271453973008, -0.41737458799120275]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import sys\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "class Optimizer:\n",
    "    #USE SAME DEFAULTS AS KERAS ADAM OPTIMIZER\n",
    "    def __init__(self, lr=.1, beta_1=0.9, beta_2=0.999,\n",
    "                 epsilon=0, decay=0., **kwargs):\n",
    "        \n",
    "        allowed_kwargs = {'clipnorm', 'clipvalue'}\n",
    "        for k in kwargs:\n",
    "            if k not in allowed_kwargs:\n",
    "                raise TypeError('Unexpected keyword argument '\n",
    "                                'passed to optimizer: ' + str(k))\n",
    "        self.__dict__.update(kwargs)\n",
    "        self.iterations = 1\n",
    "        self.lr = lr\n",
    "        self.beta_1 = beta_1\n",
    "        self.beta_2 = beta_2\n",
    "        self.decay = decay\n",
    "        self.epsilon = epsilon\n",
    "        self.initial_decay = decay\n",
    "\n",
    "    def get_ADAM(self, params, grads):\n",
    "\n",
    "        original_shapes = [x.shape for x in params]\n",
    "        params = [x.flatten() for x in params]\n",
    "        grads = [x.flatten() for x in grads]\n",
    "        \n",
    "        lr = self.lr\n",
    "        if self.initial_decay > 0:\n",
    "            lr *= (1. / (1. + self.decay * self.iterations))\n",
    "\n",
    "        t = self.iterations + 1\n",
    "        lr_t = lr * (np.sqrt(1. - np.power(self.beta_2, t)) /\n",
    "                     (1. - np.power(self.beta_1, t)))\n",
    "\n",
    "        if not hasattr(self, 'ms'):\n",
    "            self.ms = [np.zeros(p.shape) for p in params]\n",
    "            self.vs = [np.zeros(p.shape) for p in params]\n",
    "    \n",
    "        ret = [None] * len(params)\n",
    "        for i, p, g, m, v in zip(range(len(params)), params, grads, self.ms, self.vs):\n",
    "            m_t = (self.beta_1 * m) + (1. - self.beta_1) * g\n",
    "            v_t = (self.beta_2 * v) + (1. - self.beta_2) * np.square(g)\n",
    "            p_t = p - lr_t * m_t / (np.sqrt(v_t) + self.epsilon)\n",
    "            self.ms[i] = m_t\n",
    "            self.vs[i] = v_t\n",
    "            ret[i] = p_t\n",
    "        self.iterations += 1\n",
    "  \n",
    "        for i in range(len(ret)):\n",
    "            ret[i] = ret[i].reshape(original_shapes[i])\n",
    "\n",
    "        return np.array(ret)\n",
    "\n",
    "\n",
    "    def get_SGD(self, w,p):\n",
    "        for x,y in zip(w,p):\n",
    "                    x+=self.lr*y\n",
    "        return w[0],w[1],w[2],w[3],w[4],w[5],w[6],w[7],w[8],w[9]\n",
    "\n",
    "def sigmoid(x): \n",
    "    return 1. / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(values): \n",
    "    return values*(1-values)\n",
    "\n",
    "def tanh_derivative(values): \n",
    "    return 1. - values ** 2\n",
    "\n",
    "# createst uniform random array w/ values in [a,b) and shape args\n",
    "def rand_arr(a, b, *args): \n",
    "    np.random.seed(0)\n",
    "    return (np.random.rand(*args) * (b - a) + a)*.1\n",
    "\n",
    "class LstmParam:\n",
    "    def __init__(self, mem_cell_ct, x_dim,optimization):\n",
    "        self.mem_cell_ct = mem_cell_ct\n",
    "        self.x_dim = x_dim\n",
    "        concat_len = x_dim + mem_cell_ct\n",
    "        \n",
    "        self.opt=Optimizer()\n",
    "        self.optimization=optimization\n",
    "\n",
    "        # weight matrices\n",
    "        self.wg = rand_arr(-0.1, 0.1, mem_cell_ct, concat_len)\n",
    "        self.wi = rand_arr(-0.1, 0.1, mem_cell_ct, concat_len) \n",
    "        self.wf = rand_arr(-0.1, 0.1, mem_cell_ct, concat_len)\n",
    "        self.wo = rand_arr(-0.1, 0.1, mem_cell_ct, concat_len)\n",
    "\n",
    "        # bias terms\n",
    "        self.bg = rand_arr(-0.1, 0.1, mem_cell_ct) \n",
    "        self.bi = rand_arr(-0.1, 0.1, mem_cell_ct) \n",
    "        self.bf = rand_arr(-0.1, 0.1, mem_cell_ct) \n",
    "        self.bo = rand_arr(-0.1, 0.1, mem_cell_ct)\n",
    "\n",
    "\n",
    "        \n",
    "        # diffs (derivative of loss function w.r.t. all parameters)\n",
    "        self.wg_diff = np.zeros((mem_cell_ct, concat_len)) \n",
    "        self.wi_diff = np.zeros((mem_cell_ct, concat_len)) \n",
    "        self.wf_diff = np.zeros((mem_cell_ct, concat_len)) \n",
    "        self.wo_diff = np.zeros((mem_cell_ct, concat_len)) \n",
    "        self.bg_diff = np.zeros(mem_cell_ct) \n",
    "        self.bi_diff = np.zeros(mem_cell_ct) \n",
    "        self.bf_diff = np.zeros(mem_cell_ct) \n",
    "        self.bo_diff = np.zeros(mem_cell_ct) \n",
    "\n",
    "    def apply_diff(self, lr = .1):\n",
    "        if(self.optimization=='adam'):\n",
    "            self.wg=self.opt.get_ADAM(self.wg,self.wg_diff)\n",
    "            self.wi=self.opt.get_ADAM(np.array(self.wi),np.array(self.wi_diff))\n",
    "            self.wf=self.opt.get_ADAM(np.array(self.wf),np.array(self.wf_diff))\n",
    "            self.wo=self.opt.get_ADAM(np.array(self.wo),np.array(self.wo_diff))\n",
    "\n",
    "        else:\n",
    "            #This is the stochastic gradient descent code\n",
    "            self.wg -= lr * self.wg_diff\n",
    "            self.wi -= lr * self.wi_diff\n",
    "            self.wf -= lr * self.wf_diff\n",
    "            self.wo -= lr * self.wo_diff\n",
    "\n",
    "\n",
    "        \n",
    "        self.bg -= lr * self.bg_diff\n",
    "        self.bi -= lr * self.bi_diff\n",
    "        self.bf -= lr * self.bf_diff\n",
    "        self.bo -= lr * self.bo_diff\n",
    "        \n",
    "        # reset diffs to zero\n",
    "        self.wg_diff = np.zeros_like(self.wg)\n",
    "        self.wi_diff = np.zeros_like(self.wi) \n",
    "        self.wf_diff = np.zeros_like(self.wf) \n",
    "        self.wo_diff = np.zeros_like(self.wo) \n",
    "        self.bg_diff = np.zeros_like(self.bg)\n",
    "        self.bi_diff = np.zeros_like(self.bi) \n",
    "        self.bf_diff = np.zeros_like(self.bf) \n",
    "        self.bo_diff = np.zeros_like(self.bo) \n",
    "\n",
    "class LstmState:\n",
    "    def __init__(self, mem_cell_ct, x_dim):\n",
    "        self.g = np.zeros(mem_cell_ct)\n",
    "        self.i = np.zeros(mem_cell_ct)\n",
    "        self.f = np.zeros(mem_cell_ct)\n",
    "        self.o = np.zeros(mem_cell_ct)\n",
    "        self.s = np.zeros(mem_cell_ct)\n",
    "        self.h = np.zeros(mem_cell_ct)\n",
    "        self.bottom_diff_h = np.zeros_like(self.h)\n",
    "        self.bottom_diff_s = np.zeros_like(self.s)\n",
    "    \n",
    "class LstmNode:\n",
    "    def __init__(self, lstm_param, lstm_state):\n",
    "        # store reference to parameters and to activations\n",
    "        self.state = lstm_state\n",
    "        self.param = lstm_param\n",
    "\n",
    "        # non-recurrent input concatenated with recurrent input\n",
    "        self.xc = None\n",
    "\n",
    "    def bottom_data_is(self, x, s_prev = None, h_prev = None):\n",
    "        # if this is the first lstm node in the network\n",
    "        if s_prev is None: s_prev = np.zeros_like(self.state.s)\n",
    "        if h_prev is None: h_prev = np.zeros_like(self.state.h)\n",
    "        # save data for use in backprop\n",
    "        self.s_prev = s_prev\n",
    "        self.h_prev = h_prev\n",
    "\n",
    "        # concatenate x(t) and h(t-1)\n",
    "        xc = np.hstack((x,  h_prev))\n",
    "        self.state.g = np.tanh(np.dot(self.param.wg, xc) + self.param.bg)\n",
    "        self.state.i = sigmoid(np.dot(self.param.wi, xc) + self.param.bi)\n",
    "        self.state.f = sigmoid(np.dot(self.param.wf, xc) + self.param.bf)\n",
    "        self.state.o = sigmoid(np.dot(self.param.wo, xc) + self.param.bo)\n",
    "        self.state.s = self.state.g * self.state.i + s_prev * self.state.f\n",
    "        self.state.h = self.state.s * self.state.o\n",
    "\n",
    "        self.xc = xc\n",
    "\n",
    "    \n",
    "    def top_diff_is(self, top_diff_h, top_diff_s):\n",
    "        # notice that top_diff_s is carried along the constant error carousel\n",
    "        ds = self.state.o * top_diff_h + top_diff_s\n",
    "        do = self.state.s * top_diff_h\n",
    "        di = self.state.g * ds\n",
    "        dg = self.state.i * ds\n",
    "        df = self.s_prev * ds\n",
    "\n",
    "        # diffs w.r.t. vector inside sigma / tanh function\n",
    "        di_input = sigmoid_derivative(self.state.i) * di \n",
    "        df_input = sigmoid_derivative(self.state.f) * df \n",
    "        do_input = sigmoid_derivative(self.state.o) * do \n",
    "        dg_input = tanh_derivative(self.state.g) * dg\n",
    "\n",
    "        # diffs w.r.t. inputs\n",
    "        self.param.wi_diff += np.outer(di_input, self.xc)\n",
    "        self.param.wf_diff += np.outer(df_input, self.xc)\n",
    "        self.param.wo_diff += np.outer(do_input, self.xc)\n",
    "        self.param.wg_diff += np.outer(dg_input, self.xc)\n",
    "        self.param.bi_diff += di_input\n",
    "        self.param.bf_diff += df_input       \n",
    "        self.param.bo_diff += do_input\n",
    "        self.param.bg_diff += dg_input\n",
    "\n",
    "        #for dparam in [self.param.wi_diff, self.param.wf_diff , self.param.wo_diff, self.param.wg_diff, self.param.bi_diff, self.param.bf_diff, self.param.bo_diff, self.param.bg_diff]:\n",
    "        #    np.clip(dparam, -1, 1, out=dparam)\n",
    "\n",
    "        # compute bottom diff\n",
    "        dxc = np.zeros_like(self.xc)\n",
    "        dxc += np.dot(self.param.wi.T, di_input)\n",
    "        dxc += np.dot(self.param.wf.T, df_input)\n",
    "        dxc += np.dot(self.param.wo.T, do_input)\n",
    "        dxc += np.dot(self.param.wg.T, dg_input)\n",
    "\n",
    "        # save bottom diffs\n",
    "        self.state.bottom_diff_s = ds * self.state.f\n",
    "        self.state.bottom_diff_h = dxc[self.param.x_dim:]\n",
    "\n",
    "class LstmNetwork():\n",
    "    def __init__(self, lstm_param, loss):\n",
    "        self.lstm_param = lstm_param\n",
    "        self.lstm_node_list = []\n",
    "        # input sequence\n",
    "        self.x_list = []\n",
    "        self.loss=loss\n",
    "\n",
    "    def y_list_is(self, y_list, loss_layer):\n",
    "        \"\"\"\n",
    "        Updates diffs by setting target sequence \n",
    "        with corresponding loss layer. \n",
    "        Will *NOT* update parameters.  To update parameters,\n",
    "        call self.lstm_param.apply_diff()\n",
    "        \"\"\"\n",
    "        assert len(y_list) == len(self.x_list)\n",
    "        idx = len(self.x_list) - 1\n",
    "        # first node only gets diffs from label ...\n",
    "        loss = loss_layer.loss(self.lstm_node_list[idx].state.h, y_list[idx],self.loss)\n",
    "\n",
    "        diff_h =loss_layer.bottom_diff(self.lstm_node_list[idx].state.h, y_list[idx])\n",
    "\n",
    "        # here s is not affecting loss due to h(t+1), hence we set equal to zero\n",
    "        diff_s = np.zeros(self.lstm_param.mem_cell_ct)\n",
    "        self.lstm_node_list[idx].top_diff_is(diff_h, diff_s)\n",
    "        idx -= 1\n",
    "\n",
    "        ### ... following nodes also get diffs from next nodes, hence we add diffs to diff_h\n",
    "        ### we also propagate error along constant error carousel using diff_s\n",
    "        while idx >= 0:\n",
    "            loss += loss_layer.loss(self.lstm_node_list[idx].state.h, y_list[idx],self.loss)\n",
    "            diff_h = loss_layer.bottom_diff(self.lstm_node_list[idx].state.h, y_list[idx])\n",
    "            diff_h += self.lstm_node_list[idx + 1].state.bottom_diff_h\n",
    "            diff_s = self.lstm_node_list[idx + 1].state.bottom_diff_s\n",
    "            self.lstm_node_list[idx].top_diff_is(diff_h, diff_s)\n",
    "            idx -= 1 \n",
    "\n",
    "        return loss\n",
    "\n",
    "    def x_list_clear(self):\n",
    "        self.x_list = []\n",
    "\n",
    "    def x_list_add(self, x):\n",
    "        self.x_list.append(x)\n",
    "       # print(self.x_list)\n",
    "        if len(self.x_list) > len(self.lstm_node_list):\n",
    "            # need to add new lstm node, create new state mem\n",
    "            lstm_state = LstmState(self.lstm_param.mem_cell_ct, self.lstm_param.x_dim)\n",
    "            self.lstm_node_list.append(LstmNode(self.lstm_param, lstm_state))\n",
    "\n",
    "        # get index of most recent x input\n",
    "        idx = len(self.x_list) - 1\n",
    "        if idx == 0:\n",
    "            # no recurrent inputs yet\n",
    "            self.lstm_node_list[idx].bottom_data_is(x)\n",
    "        else:\n",
    "            s_prev = self.lstm_node_list[idx - 1].state.s\n",
    "            h_prev = self.lstm_node_list[idx - 1].state.h\n",
    "            self.lstm_node_list[idx].bottom_data_is(x, s_prev, h_prev)\n",
    "\n",
    "\n",
    "\n",
    "class LossLayer:\n",
    "    \"\"\"\n",
    "    Computes square loss with first element of hidden layer array.\n",
    "    MG-Attempted to add in mae loss for comparison, but RMSE and MAE loss performed the same.  \n",
    "    \"\"\"\n",
    "    @classmethod\n",
    "    def loss(self,pred, label,fn):\n",
    "        if(fn=='mae'):\n",
    "            return LossLayer.loss_mae(pred,label)\n",
    "        else:\n",
    "            return LossLayer.loss_rmse(pred,label)\n",
    "    \n",
    "    # MG added mean absolute error\n",
    "    @classmethod\n",
    "    def loss_mae(self, pred, label):\n",
    "        return (np.abs(pred[0]-label))\n",
    "        #return (pred[0] - label) ** 2\n",
    "    \n",
    "    @classmethod\n",
    "    def loss_rmse(self, pred, label):\n",
    "        return (pred[0] - label) ** 2\n",
    "\n",
    "    @classmethod\n",
    "    def bottom_diff(self, pred, label):\n",
    "        diff = np.zeros_like(pred)\n",
    "        diff[0] =2*(pred[0] - label)\n",
    "        return diff\n",
    "\n",
    "\n",
    "\n",
    "def train(loss, optimization):\n",
    "    mem_cell_ct = 50\n",
    "    x_dim = 4\n",
    "    lstm_param = LstmParam(mem_cell_ct, x_dim,optimization)\n",
    "    lstm_net = LstmNetwork(lstm_param,loss)\n",
    "    losses=[]\n",
    "    bestLoss=1e5\n",
    "    print(\"Training...\")\n",
    "    for cur_iter in range(100):\n",
    "       \n",
    "        for ind in range(len(Y)):\n",
    "            lstm_net.x_list_add(X[ind])\n",
    "\n",
    "        if(cur_iter%50==0):\n",
    "            print(\"iter\", \"%2s\" % str(cur_iter), end=\": \")\n",
    "            print(\"y_pred = [\" +\n",
    "                  \", \".join([\"% 2.5f\" % lstm_net.lstm_node_list[ind].state.h[0] for ind in range(len(Y))]) +\n",
    "                  \"]\", end=\", \")\n",
    "\n",
    "        loss = lstm_net.y_list_is(Y, LossLayer)\n",
    "        losses.append(loss)\n",
    "        if(loss<bestLoss):\n",
    "            best_lstm_net = LstmNetwork(lstm_param,loss)\n",
    "            \n",
    "        lstm_param.apply_diff(lr=0.1)\n",
    "        \n",
    "        if(cur_iter%50==0):\n",
    "            print(\"loss:\", \"%.3e\" % loss)\n",
    "\n",
    "        lstm_net.x_list_clear()\n",
    "    \n",
    "    for ind in range(len(Y)):\n",
    "        best_lstm_net.x_list_add(X[ind])   \n",
    "    loss = best_lstm_net.y_list_is(Y, LossLayer)\n",
    "    return losses, [ best_lstm_net.lstm_node_list[ind].state.h[0] for ind in range(len(Y))],loss\n",
    "\n",
    "\n",
    "\n",
    "def firstTurbineData():\n",
    "\tdf = pd.read_csv('la-haute-borne-data-2013-2016.csv', sep=';')\n",
    "\tdf['Date_time'] = df['Date_time'].astype(str).str[:-6] #remove timezone (caused me an hour of pain)\n",
    "\tdf.Date_time=pd.to_datetime(df['Date_time'])\n",
    "\tdf=df.fillna(method='ffill')\n",
    "\n",
    "\tdf=df.sort_values(by='Date_time')\n",
    "\tdf = df.reset_index()\n",
    "\tturbines=df.Wind_turbine_name.unique()\n",
    "\tprint(\"Turbine name: \"+str(turbines[0]))\n",
    "\tturbineData=df[df['Wind_turbine_name']==turbines[0]]\n",
    "\treturn turbineData\n",
    "\n",
    "\n",
    "def createGraph(losses, title):\n",
    "\tX = np.arange(0,len(losses))\n",
    "\tfigure = plt.figure()\n",
    "\ttick_plot = figure.add_subplot(1, 1, 1)\n",
    "\ttick_plot.plot(X, losses,  color='green', linestyle='-', marker='*' )\n",
    "\tplt.xlabel('Iteration')\n",
    "\tplt.ylabel('Loss')\n",
    "\tplt.title(title)\n",
    "\tplt.show()\n",
    "\n",
    "\n",
    "np.random.seed(0)\n",
    "date_to_test=datetime.datetime(2016, 1, 1)\n",
    "turbineData=np.sin(firstTurbineData().Wa_c_avg.values)[:10]\n",
    "X=np.array([turbineData[:4],\n",
    "                   turbineData[1:5],\n",
    "                   turbineData[2:6],\n",
    "                   turbineData[3:7],\n",
    "                   turbineData[4:8],\n",
    "                   turbineData[5:9]])\n",
    "Y=np.array([turbineData[4],\n",
    "                   turbineData[5],\n",
    "                   turbineData[6],\n",
    "                   turbineData[7],\n",
    "                   turbineData[8],\n",
    "                   turbineData[9]])\n",
    "\n",
    "\n",
    "losses, predictions,loss=train('rmse','sgd')\n",
    "print(\"Actual vs Predicted:\")\n",
    "print(Y)\n",
    "print(predictions)\n",
    "createGraph(losses,\"SGD Optimization\\nLoss=\"+str(loss))\n",
    "losses, predictions,loss=train('rmse','adam')\n",
    "print(\"Actual vs Predicted:\")\n",
    "print(Y)\n",
    "print(predictions)\n",
    "createGraph(losses,\"Adam Optimization\\nLoss=\"+str(loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes\n",
    "\n",
    "### Train Method Explanation: \n",
    "\n",
    "LstmParam:\n",
    "Initialize LstmParam object with hidden cell count (mem_cell_ct) and x_dim.  This object holds the networks weights, bias terms, and weight differences (derivative of loss function).  \n",
    "\n",
    "LstmNetwork:\n",
    "Holds Xlist for forward propagation. \n",
    "\n",
    "We will train the network for 100 iterations.  \n",
    "\n",
    "#### Forward propagation\n",
    "For each input value x[idx], I call the x_list_add method of the LstmNetwork:\n",
    "x_list_add:<br>\n",
    "If x_list > lstm_node_list:<br>\n",
    "- Create new LstmState.  The layers of the network should all be initialized to 0 arrays. \n",
    "- add LstmNode to lstm_node_list with LstmState with 0 arrays. \n",
    "\n",
    "If index of X input is 0:\n",
    "- Call lstm_node_list[idx].bottom_data_is(x) and forward propagate through the different inner modules of the LSTM Network.  LstmNode has \"states\" for each module, e.g. self.state.g, self.state.i.  state.s=C in the image above.  self.h and self.s get passed to the next input by being set via s_prev and h_prev, respectively. \n",
    "If index of X input is Not 0:\n",
    "- Call lstm_node_list[idx].bottom_data_is(x) and forward propagate through the different inner modules of the LSTM Network with the previous inputs s_prev and h_prev values.  \n",
    "\n",
    "Forward propagation yields the networks output guesses in its h[0] values, so we will print those periodically.  \n",
    "\n",
    "#### Calculating loss (y_list_is method):\n",
    "- input correct Y values.  To start, we take the last index from the lstm_node_list and calculate its loss by sending its h value to the loss function and returning the squared error of h[0] from its actual value, Y[idx].  \n",
    "\n",
    "- Calculate diff_h.  Find the error of the h[0] compared to the Y value.  I was unsure why Nick multiplied this error by 2, but it seemed to learn (at different rates) no matter what multiplication value you gave it.  Perhaps the 2 was to speed up learning by accentuating the loss? I'm not quite sure.  \n",
    "\n",
    "- For the last value, s (c) will be zero because it doesn't affect loss.\n",
    "\n",
    "- Backpropagate on final input value.  top_diff_is is self explanatory, computing the derivatives of each module in the LSTM layer.  \n",
    "\n",
    "- From here we backwards through the input data and perform the same back propagation: get the loss of the value compared to Y, get the loss of diff_h and diff_s, and backpropagate through the different modules.  diff_h is computed by finding the loss of the output value at the current index and then adding the loss of the value at the index+1.  diff_s is computed by getting the value of the diff_s at index+1.  \n",
    "\n",
    "#### Apply weights (apply_diff method):\n",
    "- Here is where I implemented Adam optimization.  We update weights and biases here by adding the diffs to the weights.  For example, self.wi weights are updated by adding the self.wi_diff*learning rate for SGD optimization. Adam optimization is different but follows a similar idea.  After the weights and biases are updated, we set the _diff variables back to zero.  \n",
    "\n",
    "From here we clear the x values and start another iteration. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
